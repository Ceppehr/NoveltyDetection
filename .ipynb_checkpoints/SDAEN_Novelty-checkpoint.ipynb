{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder network is an artificial neural network used for unsupervised learning of an efficient data representation (encoding), typically for the purpose of dimensionality reduction.\n",
    "\n",
    "### Vanilla Autoencoders\n",
    "An autoencoder in possibly the simplest architecture is referred to as a Vanilla autoencoder and consists of three layers, the input, the hidden, and the output layer. Basically,  given an input, Vanilla autoencoders are used to reconstruct the input at the output via a single hidden layer that has less nuerons than the input's dimension. This results in producing a bottleneck effect on the flow of information in the network, and therefore we can think of the hidden layer as a bottleneck layer, restricting the information that would be stored.\n",
    "\n",
    "### Denoising Autoencoders\n",
    "A denoising autoencoder learns from a corrupted (noisy) input; it feeds its encoder network the noisy input and then the reconstructed output from the decoder is compared with the original input. The idea is that this will help the network learn how to denoise an input. Thus learning its core features.\n",
    "\n",
    "### Stacked Denoising Autoencoders\n",
    "It is possible to have multiple layers in encoder and decoder segments of the network. Using deeper encoder and decoder networks can allow the autoencoder to represent complex features. The structure so obtained is called a *stacked autoencoder* (deep autoencoders); the features extracted by one encoder are passed on to the next encoder as input. The stackedÂ  autoencoder can be trained as a whole network with an aim to minimise the reconstruction error.\n",
    "\n",
    "### Tensorflow Implementation\n",
    "For implementation, I use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) of handwritten digits.\n",
    "\n",
    "\n",
    "<img style=\"float: center;\" src=\"https://github.com/Ceppehr/NoveltyDetection/blob/master/Images/mnist.png?raw=true\">\n",
    "\n",
    "\n",
    "\n",
    "The inputs to the autoencoder are the noisy digits so as the first step, let's apply some noise to corrupt our input **x**:\n",
    "\n",
    "<img style=\"float: center;\" src=\"https://github.com/Ceppehr/NoveltyDetection/blob/master/Images/DAEN.png?raw=true\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> Preamble </center><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import xlrd\n",
    "\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> Methods and Classes </center><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepAutoEncoder(object):\n",
    "    def __init__(self, list1, eta=0.02):\n",
    "        \"\"\"\n",
    "        :param list1: [input_dimension, hidden_layer_1, ..., hidden_layer_n]\n",
    "        :param eta: Learning rate\n",
    "        \"\"\"\n",
    "        N = len(list1) - 1\n",
    "        self._m = list1[0]\n",
    "        self.learning_rate = eta\n",
    "        \n",
    "        # Create Computational Graph\n",
    "        self._W = {}\n",
    "        self._b = {}\n",
    "        self._X = {}\n",
    "        \n",
    "        # -- Placeholder for inputs\n",
    "        self._X['0'] = tf.placeholder('float', shape=[None, list1[0]])\n",
    "        self._X_noisy = tf.placeholder('float', shape=[None, self._m])\n",
    "        \n",
    "        # -- Weights and biases\n",
    "        for i in range(N):\n",
    "            layer = '{0}'.format(i+1)\n",
    "            print(\"AutoEncoder layer {0} : {1}-->{2}\".format(layer, list1[i], list1[i+1]))\n",
    "            self._W['E' + layer] = tf.Variable(tf.random_normal(shape=(list1[i], list1[i+1])),\n",
    "                                              name='WtsEncoder'+layer)\n",
    "            self._b['E' + layer] = tf.Variable(np.zeros(list1[i+1]).astype(np.float32),\n",
    "                                               name='BiasEncoder' + layer)\n",
    "            self._X[layer] = tf.placeholder('float', shape=[None, list1[i+1]])\n",
    "            self._W['D' + layer] = tf.transpose(self._W['E' + layer]) #Shared weight\n",
    "            self._b['D' + layer] = tf.Variable(np.zeros(list1[i]).astype(np.float32),\n",
    "                                              name='BiasDecoder' + layer)\n",
    "            \n",
    "        \n",
    "        # -- Pretraining\n",
    "        self.train_ops = {}\n",
    "        self.out = {}\n",
    "        for i in range(N):\n",
    "            layer = '{0}'.format(i+1)\n",
    "            prev_layer = '{0}'.format(i)\n",
    "            opt = self.pretrain(self._X[prev_layer], layer)\n",
    "            self.train_ops[layer] = opt\n",
    "            self.out[layer] = self.one_pass(self._X[prev_layer], self._W['E' + layer],\n",
    "                                           self._b['E' + layer])\n",
    "        \n",
    "        self.y = self.encoder(self._X_noisy, N) #Encoder output\n",
    "        self.r = self.decoder(self.y, N) #Decoder output\n",
    "        \n",
    "        optimiser = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        error = self._X['0'] - self.r #Reconstruction error\n",
    "        \n",
    "        self._loss = tf.losses.mean_squared_error(self._X['0'], self.r)\n",
    "        self._opt = optimiser.minimize(self._loss)\n",
    "        \n",
    "    # Methods\n",
    "    \n",
    "    def encoder(self, X, N):\n",
    "        x = X #original input\n",
    "        for i in range(N):\n",
    "            layer = '{0}'.format(i+1)\n",
    "            hiddenE = tf.nn.sigmoid(tf.add(tf.matmul(x, self._W['E' + layer]), self._b['E' + layer]))\n",
    "            x = hiddenE #new input for the next layer\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, X, N):\n",
    "        x = X\n",
    "        for i in range(N, 0, -1):\n",
    "            layer = '{0}'.format(i)\n",
    "            hiddenD = tf.nn.sigmoid(tf.add(tf.matmul(x, self._W['D' + layer]), self._b['D' + layer]))\n",
    "            x = hiddenD\n",
    "        return x\n",
    "    \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        \n",
    "    def reconstruct(self, x, n_layers):\n",
    "        h = self.encoder(x, n_layers)\n",
    "        r = self.decoder(h, n_layers)\n",
    "        return self.session.run(r, feed_dict={self._X['0']:x})\n",
    "    \n",
    "    def pretrain(self, X, layer):\n",
    "        y = tf.nn.sigmoid(tf.add(tf.matmul(X, self._W['E' + layer]), self._b['E' + layer]))\n",
    "        r = tf.nn.sigmoid(tf.add(tf.matmul(y, self._W['D' + layer]), self._b['D' + layer]))\n",
    "        loss = tf.losses.mean_squared_error(X, r)\n",
    "        opt = tf.train.AdamOptimizer(0.001).minimize(loss, var_list=[self._W['E' + layer], self._b['E' + layer]])\n",
    "        return opt\n",
    "    \n",
    "    def one_pass(self, X, W, b):\n",
    "        h = tf.nn.sigmoid(tf.add(tf.matmul(X, W), b))\n",
    "        return h\n",
    "    \n",
    "    def getWeights(self, N):\n",
    "        return self.session.run([self._W['E' + str(N)], self._W['D' + str(N)], self._b['E' + str(N)], self._b['D' + str(N)]])\n",
    "        \n",
    "    def fit(self, Xtrain, Xtr_noisy, layers, epochs=1, batch_size=100):\n",
    "        N, D = Xtrain.shape\n",
    "        num_batches = N//batch_size\n",
    "        X_noisy = {}\n",
    "        X = {}\n",
    "        X_noisy['0'] = Xtr_noisy\n",
    "        X['0'] = Xtrain\n",
    "        for i in range(layers):\n",
    "            Xin = X[str(i)]\n",
    "            print('Pretraining Layer ', i+1)\n",
    "            for e in range(5):\n",
    "                for j in range(num_batches):\n",
    "                    batch = Xin[j*batch_size:(j*batch_size+batch_size)]\n",
    "                    self.session.run(self.train_ops[str(i+1)], feed_dict={self._X[str(i)]:batch})\n",
    "            print(\"Pretraining Finished!\")\n",
    "            X[str(i+1)] = self.session.run(self.out[str(i+1)], feed_dict={self._X[str(i)]:Xin})\n",
    "            \n",
    "        obj=[]\n",
    "        for i in range(epochs):\n",
    "            for j in range(num_batches):\n",
    "                batch = Xtrain[j*batch_size:(j*batch_size+batch_size)]\n",
    "                batch_noisy = Xtr_noisy[j*batch_size:(j*batch_size+batch_size)]\n",
    "                _, ob = self.session.run([self._opt, self._loss], feed_dict={self._X['0']:batch,\n",
    "                                                                            self._X_noisy:batch_noisy})\n",
    "                if j%100==0:\n",
    "                    print(\"Training epoch {0} batch{1} loss {2}\".format(i, j, ob))\n",
    "                obj.append(ob)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "omega = 1.\n",
    "\n",
    "class ELM(object):\n",
    "    def __init__(self, sess, batch_size, input_len, hidden_num, output_len):\n",
    "        '''\n",
    "        Args:\n",
    "          sess : TensorFlow session.\n",
    "          batch_size : The batch size (N)\n",
    "          input_len : The length of input. (L)\n",
    "          hidden_num : The number of hidden node. (K)\n",
    "          output_len : The length of output. (O)\n",
    "        '''\n",
    "    \n",
    "        self._sess = sess \n",
    "        self._batch_size = batch_size\n",
    "        self._input_len = input_len\n",
    "        self._hidden_num = hidden_num\n",
    "        self._output_len = output_len \n",
    "\n",
    "        # for train\n",
    "        self._x0 = tf.placeholder(tf.float32, [self._batch_size, self._input_len])\n",
    "        self._t0 = tf.placeholder(tf.float32, [self._batch_size, self._output_len])\n",
    "\n",
    "        # for test\n",
    "        self._x1 = tf.placeholder(tf.float32, [None, self._input_len])\n",
    "        self._t1 = tf.placeholder(tf.float32, [None, self._output_len])\n",
    "\n",
    "        self._W = tf.Variable(\n",
    "          tf.random_normal([self._input_len, self._hidden_num]),\n",
    "          trainable=False, dtype=tf.float32)\n",
    "        self._b = tf.Variable(\n",
    "          tf.random_normal([self._hidden_num]),\n",
    "          trainable=False, dtype=tf.float32)\n",
    "        self._beta = tf.Variable(\n",
    "          tf.zeros([self._hidden_num, self._output_len]),\n",
    "          trainable=False, dtype=tf.float32)\n",
    "        self._var_list = [self._W, self._b, self._beta]\n",
    "\n",
    "        self.H0 = tf.matmul(self._x0, self._W) + self._b # N x L\n",
    "        self.H0_T = tf.transpose(self.H0)\n",
    "\n",
    "        self.H1 = tf.matmul(self._x1, self._W) + self._b # N x L\n",
    "        self.H1_T = tf.transpose(self.H1)\n",
    "\n",
    "        # beta analytic solution : self._beta_s (K x O)\n",
    "        if self._input_len < self._hidden_num: # L < K\n",
    "            identity = tf.constant(np.identity(self._hidden_num), dtype=tf.float32)\n",
    "            self._beta_s = tf.matmul(tf.matmul(tf.matrix_inverse(\n",
    "                tf.matmul(self.H0_T, self.H0) + identity/omega), self.H0_T), self._t0)\n",
    "          # _beta_s = (H_T*H + I/om)^(-1)*H_T*T\n",
    "        else:\n",
    "            identity = tf.constant(np.identity(self._batch_size), dtype=tf.float32)\n",
    "            self._beta_s = tf.matmul(tf.matmul(self.H0_T, tf.matrix_inverse(\n",
    "                tf.matmul(self.H0, self.H0_T)+identity/omega)), self._t0)\n",
    "                # _beta_s = H_T*(H*H_T + I/om)^(-1)*T\n",
    "\n",
    "        self._assign_beta = self._beta.assign(self._beta_s)\n",
    "        self._fx0 = tf.matmul(self.H0, self._beta)\n",
    "        self._fx1 = tf.matmul(self.H1, self._beta)\n",
    "\n",
    "        self._cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self._fx0, labels=self._t0))\n",
    "\n",
    "        self._init = False\n",
    "        self._feed = False\n",
    "\n",
    "        # for the mnist test\n",
    "        self._correct_prediction = tf.equal(tf.argmax(self._fx1,1), tf.argmax(self._t1,1))\n",
    "        self._accuracy = tf.reduce_mean(tf.cast(self._correct_prediction, tf.float32))\n",
    "\n",
    "    def feed(self, x, t):\n",
    "        '''\n",
    "        Args :\n",
    "          x : input array (N x L)\n",
    "          t : label array (N x O)\n",
    "        '''\n",
    "\n",
    "        if not self._init : self.init()\n",
    "        self._sess.run(self._assign_beta, {self._x0:x, self._t0:t})\n",
    "        self._feed = True\n",
    "\n",
    "    def init(self):\n",
    "        self._sess.run(tf.initialize_variables(self._var_list))\n",
    "        self._init = True\n",
    "\n",
    "    def test(self, x, t=None):\n",
    "        if not self._feed : exit(\"Not feed-forward trained\")\n",
    "        if t is not None :\n",
    "            print(\"Accuracy: {:.9f}\".format(self._sess.run(self._accuracy, {self._x1:x, self._t1:t})))\n",
    "        else :\n",
    "            return self._sess.run(self._fx1, {self._x1:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> Data </center><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot=False)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
